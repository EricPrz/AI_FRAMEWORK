{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"../data/mnist_train.csv\")\n",
    "test = pd.read_csv(\"../data/mnist_test.csv\")\n",
    "\n",
    "# Reestructuring\n",
    "train_label, train_image = train[\"label\"].to_numpy(), train[[x for x in train.columns if x != \"label\"]].to_numpy().reshape((-1, 1, 28, 28))/255\n",
    "test_label, test_image = train[\"label\"].to_numpy(), train[[x for x in train.columns if x != \"label\"]].to_numpy().reshape((-1, 1, 28, 28))/255\n",
    "\n",
    "# One-hotting\n",
    "one_hot = np.zeros((len(train_label), 10))\n",
    "for label in range(train_label.shape[0]):\n",
    "    one_hot[label, train_label[label]] = 1\n",
    "train_label = one_hot\n",
    "\n",
    "one_hot = np.zeros((len(test_label), 10))\n",
    "for label in range(test_label.shape[0]):\n",
    "    one_hot[label, test_label[label]] = 1\n",
    "test_label = one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import framework as fm\n",
    "\n",
    "class Model(fm.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = fm.Conv2d(1, 6, 5, 1, bias = False)\n",
    "        self.relu1 = fm.ReLu()\n",
    "        self.maxpool1 = fm.MaxPool2d(2, 6, 2)\n",
    "\n",
    "        self.conv2 = fm.Conv2d(6, 16, 5, 1, bias = False)\n",
    "        self.maxpool2 = fm.MaxPool2d(2, 16, 2)\n",
    "        self.bn1 = fm.BatchNorm(1)\n",
    "        self.lin1 = fm.Linear(256, 84, bias=False)\n",
    "        self.bn2 = fm.BatchNorm(1)\n",
    "        self.drop2 = fm.Dropout(0.2)\n",
    "        self.lin2 = fm.Linear(84, 10, bias=False)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1.forward(x) \n",
    "        x = self.relu1.forward(x) \n",
    "        x = self.maxpool1.forward(x)\n",
    "        x = self.conv2.forward(x)\n",
    "        x = self.maxpool2.forward(x)\n",
    "        x = x.reshape((-1, 256))\n",
    "        x = self.bn1.forward(x)\n",
    "        x = self.lin1.forward(x) \n",
    "        x = self.bn2.forward(x)\n",
    "        x = self.drop2.forward(x)\n",
    "        x = self.lin2.forward(x)\n",
    "        return x\n",
    "\n",
    "model = Model()\n",
    "model.train()\n",
    "loss_fn = fm.CrossEntropy()\n",
    "optim = fm.Adadelta(model.get_parameters())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x, y, batch_size, loss_fn, optim):\n",
    "\n",
    "    num_batches = int(len(y)/batch_size)\n",
    "\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for batch in range(num_batches):\n",
    "        batch_start, batch_end = (batch * batch_size, (batch + 1) * batch_size)\n",
    "\n",
    "        inpt = fm.Tensor(x[batch_start:batch_end])\n",
    "        label = fm.Tensor(y[batch_start:batch_end])\n",
    "        \n",
    "        pred = model.forward(inpt)\n",
    "    \n",
    "        pred_nums = np.argmax(pred.data, axis=1)\n",
    "        label_nums = np.argmax(label.data, axis=1)\n",
    "\n",
    "        correct = (pred_nums == label_nums).sum()\n",
    "        \n",
    "        loss = loss_fn.forward(pred, label)\n",
    "\n",
    "        total_loss += loss \n",
    "        total_correct += correct\n",
    "\n",
    "        if batch % int(num_batches/10) == 0:\n",
    "            print(f\"loss: {loss} [{(batch+1)*batch_size}/{batch_size*num_batches}]\")   \n",
    "      \n",
    "        loss_fn.backward()\n",
    "        optim.step()\n",
    "\n",
    "    total_loss /= num_batches\n",
    "    total_correct /= num_batches * batch_size\n",
    "\n",
    "    print(\"Avg error: \", total_loss)\n",
    "    print(\"Train Precision: \", total_correct, \"\\n\")  \n",
    "\n",
    "    return total_loss, total_correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, x, y, batch_size):\n",
    "    model.test()\n",
    "    correct = 0\n",
    "    batch_size = 128\n",
    "    num_batches = int(len(y)/batch_size)\n",
    "    for batch in range(num_batches):\n",
    "            batch_start, batch_end = (batch * batch_size, (batch + 1) * batch_size)\n",
    "\n",
    "            inpt = fm.Tensor(x[batch_start:batch_end])\n",
    "            label = fm.Tensor(y[batch_start:batch_end])\n",
    "            \n",
    "            pred = model.forward(inpt)\n",
    "\n",
    "            pred_nums = np.argmax(pred.data, axis=1)\n",
    "            label_nums = np.argmax(label.data, axis=1)\n",
    "\n",
    "            correct += (pred_nums == label_nums).sum()\n",
    "\n",
    "    correct /= batch_size * num_batches\n",
    "\n",
    "    print(\"Test Accuracy:\", correct * 100, \"%\\n\")\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.869347095489502 [128/59904]\n",
      "loss: 0.597331166267395 [6016/59904]\n",
      "loss: 0.6749674081802368 [11904/59904]\n",
      "loss: 0.5430814623832703 [17792/59904]\n",
      "loss: 0.43444833159446716 [23680/59904]\n",
      "loss: 0.31527289748191833 [29568/59904]\n",
      "loss: 0.2771932780742645 [35456/59904]\n",
      "loss: 0.4674035310745239 [41344/59904]\n",
      "loss: 0.21692675352096558 [47232/59904]\n",
      "loss: 0.23428824543952942 [53120/59904]\n",
      "loss: 0.05379745364189148 [59008/59904]\n",
      "Avg error:  0.45816857\n",
      "Train Precision:  0.8544170673076923 \n",
      "\n",
      "Test Accuracy: 92.56810897435898 %\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.2368735671043396 [128/59904]\n",
      "loss: 0.1783764660358429 [6016/59904]\n",
      "loss: 0.25972092151641846 [11904/59904]\n",
      "loss: 0.27584555745124817 [17792/59904]\n",
      "loss: 0.22613418102264404 [23680/59904]\n",
      "loss: 0.13181421160697937 [29568/59904]\n",
      "loss: 0.10659414529800415 [35456/59904]\n",
      "loss: 0.29942119121551514 [41344/59904]\n",
      "loss: 0.11493083834648132 [47232/59904]\n",
      "loss: 0.1422429084777832 [53120/59904]\n",
      "loss: 0.022569924592971802 [59008/59904]\n",
      "Avg error:  0.19522539\n",
      "Train Precision:  0.9414396367521367 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.14190980792045593 [128/59904]\n",
      "loss: 0.09715507924556732 [6016/59904]\n",
      "loss: 0.21975818276405334 [11904/59904]\n",
      "loss: 0.20806989073753357 [17792/59904]\n",
      "loss: 0.1953102946281433 [23680/59904]\n",
      "loss: 0.08972714841365814 [29568/59904]\n",
      "loss: 0.06628666818141937 [35456/59904]\n",
      "loss: 0.25409549474716187 [41344/59904]\n",
      "loss: 0.08360123634338379 [47232/59904]\n",
      "loss: 0.09931647777557373 [53120/59904]\n",
      "loss: 0.017072448506951332 [59008/59904]\n",
      "Avg error:  0.14546081\n",
      "Train Precision:  0.9567307692307693 \n",
      "\n",
      "Test Accuracy: 96.00861378205127 %\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.10820885002613068 [128/59904]\n",
      "loss: 0.07367285341024399 [6016/59904]\n",
      "loss: 0.19428589940071106 [11904/59904]\n",
      "loss: 0.15903730690479279 [17792/59904]\n",
      "loss: 0.19224362075328827 [23680/59904]\n",
      "loss: 0.07538135349750519 [29568/59904]\n",
      "loss: 0.050056666135787964 [35456/59904]\n",
      "loss: 0.21637581288814545 [41344/59904]\n",
      "loss: 0.07114487886428833 [47232/59904]\n",
      "loss: 0.09524983167648315 [53120/59904]\n",
      "loss: 0.015110880136489868 [59008/59904]\n",
      "Avg error:  0.12144924\n",
      "Train Precision:  0.9632578792735043 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.0941014438867569 [128/59904]\n",
      "loss: 0.06190146505832672 [6016/59904]\n",
      "loss: 0.17513908445835114 [11904/59904]\n",
      "loss: 0.1328870952129364 [17792/59904]\n",
      "loss: 0.17523184418678284 [23680/59904]\n",
      "loss: 0.06600967049598694 [29568/59904]\n",
      "loss: 0.04280690848827362 [35456/59904]\n",
      "loss: 0.19108256697654724 [41344/59904]\n",
      "loss: 0.06233442574739456 [47232/59904]\n",
      "loss: 0.0907951146364212 [53120/59904]\n",
      "loss: 0.014289271086454391 [59008/59904]\n",
      "Avg error:  0.10613861\n",
      "Train Precision:  0.9671641292735043 \n",
      "\n",
      "Test Accuracy: 96.95846688034187 %\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.08341825008392334 [128/59904]\n",
      "loss: 0.05441327393054962 [6016/59904]\n",
      "loss: 0.16173413395881653 [11904/59904]\n",
      "loss: 0.11874543130397797 [17792/59904]\n",
      "loss: 0.153811514377594 [23680/59904]\n",
      "loss: 0.05853353813290596 [29568/59904]\n",
      "loss: 0.040416546165943146 [35456/59904]\n",
      "loss: 0.1679128110408783 [41344/59904]\n",
      "loss: 0.04996658116579056 [47232/59904]\n",
      "loss: 0.08371322602033615 [53120/59904]\n",
      "loss: 0.010371940210461617 [59008/59904]\n",
      "Avg error:  0.09466792\n",
      "Train Precision:  0.9713207799145299 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.07641809433698654 [128/59904]\n",
      "loss: 0.051892686635255814 [6016/59904]\n",
      "loss: 0.15975914895534515 [11904/59904]\n",
      "loss: 0.10728901624679565 [17792/59904]\n",
      "loss: 0.13459162414073944 [23680/59904]\n",
      "loss: 0.05585349723696709 [29568/59904]\n",
      "loss: 0.03753841295838356 [35456/59904]\n",
      "loss: 0.15163534879684448 [41344/59904]\n",
      "loss: 0.043892890214920044 [47232/59904]\n",
      "loss: 0.075694739818573 [53120/59904]\n",
      "loss: 0.00832662358880043 [59008/59904]\n",
      "Avg error:  0.08628868\n",
      "Train Precision:  0.9737580128205128 \n",
      "\n",
      "Test Accuracy: 97.50600961538461 %\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.07507142424583435 [128/59904]\n",
      "loss: 0.04825875163078308 [6016/59904]\n",
      "loss: 0.15823355317115784 [11904/59904]\n",
      "loss: 0.09679020196199417 [17792/59904]\n",
      "loss: 0.1187831312417984 [23680/59904]\n",
      "loss: 0.05243755131959915 [29568/59904]\n",
      "loss: 0.03234047442674637 [35456/59904]\n",
      "loss: 0.13669905066490173 [41344/59904]\n",
      "loss: 0.04027460515499115 [47232/59904]\n",
      "loss: 0.07314975559711456 [53120/59904]\n",
      "loss: 0.006253629457205534 [59008/59904]\n",
      "Avg error:  0.07925059\n",
      "Train Precision:  0.975761217948718 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.06881145387887955 [128/59904]\n",
      "loss: 0.04460391402244568 [6016/59904]\n",
      "loss: 0.15476681292057037 [11904/59904]\n",
      "loss: 0.0879504457116127 [17792/59904]\n",
      "loss: 0.1049661785364151 [23680/59904]\n",
      "loss: 0.04941759631037712 [29568/59904]\n",
      "loss: 0.027890929952263832 [35456/59904]\n",
      "loss: 0.1252574622631073 [41344/59904]\n",
      "loss: 0.039486076682806015 [47232/59904]\n",
      "loss: 0.07240252196788788 [53120/59904]\n",
      "loss: 0.00519046513363719 [59008/59904]\n",
      "Avg error:  0.07340799\n",
      "Train Precision:  0.9774973290598291 \n",
      "\n",
      "Test Accuracy: 97.87159455128204 %\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.064681775867939 [128/59904]\n",
      "loss: 0.04274486377835274 [6016/59904]\n",
      "loss: 0.15224462747573853 [11904/59904]\n",
      "loss: 0.08314169943332672 [17792/59904]\n",
      "loss: 0.09308589994907379 [23680/59904]\n",
      "loss: 0.04814332723617554 [29568/59904]\n",
      "loss: 0.025605082511901855 [35456/59904]\n",
      "loss: 0.12064636498689651 [41344/59904]\n",
      "loss: 0.03900248184800148 [47232/59904]\n",
      "loss: 0.0729462206363678 [53120/59904]\n",
      "loss: 0.004465819802135229 [59008/59904]\n",
      "Avg error:  0.06878204\n",
      "Train Precision:  0.9787660256410257 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.06603308767080307 [128/59904]\n",
      "loss: 0.04460747539997101 [6016/59904]\n",
      "loss: 0.1445418894290924 [11904/59904]\n",
      "loss: 0.08255753666162491 [17792/59904]\n",
      "loss: 0.07718925923109055 [23680/59904]\n",
      "loss: 0.04683920368552208 [29568/59904]\n",
      "loss: 0.02331123687326908 [35456/59904]\n",
      "loss: 0.11508408188819885 [41344/59904]\n",
      "loss: 0.03905076906085014 [47232/59904]\n",
      "loss: 0.06911669671535492 [53120/59904]\n",
      "loss: 0.003876150818541646 [59008/59904]\n",
      "Avg error:  0.065348744\n",
      "Train Precision:  0.9797342414529915 \n",
      "\n",
      "Test Accuracy: 98.06857638888889 %\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.06710422039031982 [128/59904]\n",
      "loss: 0.04674685001373291 [6016/59904]\n",
      "loss: 0.1406213492155075 [11904/59904]\n",
      "loss: 0.07957294583320618 [17792/59904]\n",
      "loss: 0.06938952207565308 [23680/59904]\n",
      "loss: 0.04603252932429314 [29568/59904]\n",
      "loss: 0.02160152606666088 [35456/59904]\n",
      "loss: 0.11612871289253235 [41344/59904]\n",
      "loss: 0.0389699786901474 [47232/59904]\n",
      "loss: 0.06497451663017273 [53120/59904]\n",
      "loss: 0.0032219195272773504 [59008/59904]\n",
      "Avg error:  0.062201183\n",
      "Train Precision:  0.9808360042735043 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.0646635890007019 [128/59904]\n",
      "loss: 0.04799289628863335 [6016/59904]\n",
      "loss: 0.1359235942363739 [11904/59904]\n",
      "loss: 0.07519060373306274 [17792/59904]\n",
      "loss: 0.06611862033605576 [23680/59904]\n",
      "loss: 0.04601819068193436 [29568/59904]\n",
      "loss: 0.01923191174864769 [35456/59904]\n",
      "loss: 0.11612267792224884 [41344/59904]\n",
      "loss: 0.03675852715969086 [47232/59904]\n",
      "loss: 0.06065768748521805 [53120/59904]\n",
      "loss: 0.0026817102916538715 [59008/59904]\n",
      "Avg error:  0.058873124\n",
      "Train Precision:  0.9820880074786325 \n",
      "\n",
      "Test Accuracy: 98.27223557692307 %\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.06101026013493538 [128/59904]\n",
      "loss: 0.05036318674683571 [6016/59904]\n",
      "loss: 0.13589173555374146 [11904/59904]\n",
      "loss: 0.07169678807258606 [17792/59904]\n",
      "loss: 0.061944469809532166 [23680/59904]\n",
      "loss: 0.04791904240846634 [29568/59904]\n",
      "loss: 0.01728217676281929 [35456/59904]\n",
      "loss: 0.11626671254634857 [41344/59904]\n",
      "loss: 0.0352247878909111 [47232/59904]\n",
      "loss: 0.05560719966888428 [53120/59904]\n",
      "loss: 0.002407565712928772 [59008/59904]\n",
      "Avg error:  0.055887826\n",
      "Train Precision:  0.9831063034188035 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.05482024326920509 [128/59904]\n",
      "loss: 0.05231671780347824 [6016/59904]\n",
      "loss: 0.12999878823757172 [11904/59904]\n",
      "loss: 0.06858450919389725 [17792/59904]\n",
      "loss: 0.055463165044784546 [23680/59904]\n",
      "loss: 0.04576629772782326 [29568/59904]\n",
      "loss: 0.016252536326646805 [35456/59904]\n",
      "loss: 0.11569155752658844 [41344/59904]\n",
      "loss: 0.03428477793931961 [47232/59904]\n",
      "loss: 0.05116749554872513 [53120/59904]\n",
      "loss: 0.0020664003677666187 [59008/59904]\n",
      "Avg error:  0.053268977\n",
      "Train Precision:  0.984107905982906 \n",
      "\n",
      "Test Accuracy: 98.45586271367522 %\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.049914345145225525 [128/59904]\n",
      "loss: 0.054885443300008774 [6016/59904]\n",
      "loss: 0.12798047065734863 [11904/59904]\n",
      "loss: 0.06412455439567566 [17792/59904]\n",
      "loss: 0.0526399090886116 [23680/59904]\n",
      "loss: 0.044923290610313416 [29568/59904]\n",
      "loss: 0.014731432311236858 [35456/59904]\n",
      "loss: 0.1172097846865654 [41344/59904]\n",
      "loss: 0.032499078661203384 [47232/59904]\n",
      "loss: 0.05062265694141388 [53120/59904]\n",
      "loss: 0.0018495541298761964 [59008/59904]\n",
      "Avg error:  0.05081553\n",
      "Train Precision:  0.9848090277777778 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.04673031345009804 [128/59904]\n",
      "loss: 0.0541703999042511 [6016/59904]\n",
      "loss: 0.12848353385925293 [11904/59904]\n",
      "loss: 0.05895096808671951 [17792/59904]\n",
      "loss: 0.050571370869874954 [23680/59904]\n",
      "loss: 0.04572170227766037 [29568/59904]\n",
      "loss: 0.013837164267897606 [35456/59904]\n",
      "loss: 0.11992456763982773 [41344/59904]\n",
      "loss: 0.032417502254247665 [47232/59904]\n",
      "loss: 0.04718981683254242 [53120/59904]\n",
      "loss: 0.0016183691332116723 [59008/59904]\n",
      "Avg error:  0.048554048\n",
      "Train Precision:  0.9858106303418803 \n",
      "\n",
      "Test Accuracy: 98.5526842948718 %\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.04491201043128967 [128/59904]\n",
      "loss: 0.05771734565496445 [6016/59904]\n",
      "loss: 0.12838906049728394 [11904/59904]\n",
      "loss: 0.05555092170834541 [17792/59904]\n",
      "loss: 0.047412775456905365 [23680/59904]\n",
      "loss: 0.045345112681388855 [29568/59904]\n",
      "loss: 0.013051899150013924 [35456/59904]\n",
      "loss: 0.12126000970602036 [41344/59904]\n",
      "loss: 0.028351916000247 [47232/59904]\n",
      "loss: 0.044307563453912735 [53120/59904]\n",
      "loss: 0.0015442627482116222 [59008/59904]\n",
      "Avg error:  0.04641398\n",
      "Train Precision:  0.9867454594017094 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.03897574171423912 [128/59904]\n",
      "loss: 0.05943287909030914 [6016/59904]\n",
      "loss: 0.12500229477882385 [11904/59904]\n",
      "loss: 0.054167669266462326 [17792/59904]\n",
      "loss: 0.044152531772851944 [23680/59904]\n",
      "loss: 0.04186685010790825 [29568/59904]\n",
      "loss: 0.012448733672499657 [35456/59904]\n",
      "loss: 0.12080273777246475 [41344/59904]\n",
      "loss: 0.025337055325508118 [47232/59904]\n",
      "loss: 0.04057905077934265 [53120/59904]\n",
      "loss: 0.0014093999052420259 [59008/59904]\n",
      "Avg error:  0.044228423\n",
      "Train Precision:  0.9876302083333334 \n",
      "\n",
      "Test Accuracy: 98.73297275641025 %\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.03626614063978195 [128/59904]\n",
      "loss: 0.05877289921045303 [6016/59904]\n",
      "loss: 0.12493515759706497 [11904/59904]\n",
      "loss: 0.04973308742046356 [17792/59904]\n",
      "loss: 0.041886426508426666 [23680/59904]\n",
      "loss: 0.03831437975168228 [29568/59904]\n",
      "loss: 0.01143646240234375 [35456/59904]\n",
      "loss: 0.11818116903305054 [41344/59904]\n",
      "loss: 0.025009430944919586 [47232/59904]\n",
      "loss: 0.036985110491514206 [53120/59904]\n",
      "loss: 0.0013096962356939912 [59008/59904]\n",
      "Avg error:  0.042215835\n",
      "Train Precision:  0.9882311698717948 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.03308393433690071 [128/59904]\n",
      "loss: 0.06038869544863701 [6016/59904]\n",
      "loss: 0.12306341528892517 [11904/59904]\n",
      "loss: 0.04719967395067215 [17792/59904]\n",
      "loss: 0.03703789412975311 [23680/59904]\n",
      "loss: 0.03724772483110428 [29568/59904]\n",
      "loss: 0.011233367957174778 [35456/59904]\n",
      "loss: 0.11453796923160553 [41344/59904]\n",
      "loss: 0.02342982217669487 [47232/59904]\n",
      "loss: 0.03514299541711807 [53120/59904]\n",
      "loss: 0.0012868698686361313 [59008/59904]\n",
      "Avg error:  0.040409185\n",
      "Train Precision:  0.9890491452991453 \n",
      "\n",
      "Test Accuracy: 98.84648771367522 %\n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.028940338641405106 [128/59904]\n",
      "loss: 0.06016630679368973 [6016/59904]\n",
      "loss: 0.12189783155918121 [11904/59904]\n",
      "loss: 0.04693877696990967 [17792/59904]\n",
      "loss: 0.03272484615445137 [23680/59904]\n",
      "loss: 0.03728720545768738 [29568/59904]\n",
      "loss: 0.010934697464108467 [35456/59904]\n",
      "loss: 0.11404663324356079 [41344/59904]\n",
      "loss: 0.02306544780731201 [47232/59904]\n",
      "loss: 0.030990123748779297 [53120/59904]\n",
      "loss: 0.0012081996537745 [59008/59904]\n",
      "Avg error:  0.03874487\n",
      "Train Precision:  0.9896834935897436 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.026813875883817673 [128/59904]\n",
      "loss: 0.059714142233133316 [6016/59904]\n",
      "loss: 0.11814562976360321 [11904/59904]\n",
      "loss: 0.04210374504327774 [17792/59904]\n",
      "loss: 0.030058573931455612 [23680/59904]\n",
      "loss: 0.03612257167696953 [29568/59904]\n",
      "loss: 0.010631071403622627 [35456/59904]\n",
      "loss: 0.1133195161819458 [41344/59904]\n",
      "loss: 0.021527813747525215 [47232/59904]\n",
      "loss: 0.0275892224162817 [53120/59904]\n",
      "loss: 0.0012022965820506215 [59008/59904]\n",
      "Avg error:  0.03708064\n",
      "Train Precision:  0.9904013087606838 \n",
      "\n",
      "Test Accuracy: 98.89823717948718 %\n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.024696601554751396 [128/59904]\n",
      "loss: 0.05813545733690262 [6016/59904]\n",
      "loss: 0.1162194311618805 [11904/59904]\n",
      "loss: 0.03923221677541733 [17792/59904]\n",
      "loss: 0.027176398783922195 [23680/59904]\n",
      "loss: 0.03385792300105095 [29568/59904]\n",
      "loss: 0.009450948797166348 [35456/59904]\n",
      "loss: 0.10935667902231216 [41344/59904]\n",
      "loss: 0.020822273567318916 [47232/59904]\n",
      "loss: 0.023794598877429962 [53120/59904]\n",
      "loss: 0.0010477601317688823 [59008/59904]\n",
      "Avg error:  0.035533823\n",
      "Train Precision:  0.9909688835470085 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.02301185019314289 [128/59904]\n",
      "loss: 0.05718698352575302 [6016/59904]\n",
      "loss: 0.1102345883846283 [11904/59904]\n",
      "loss: 0.03588308393955231 [17792/59904]\n",
      "loss: 0.025194119662046432 [23680/59904]\n",
      "loss: 0.03232693672180176 [29568/59904]\n",
      "loss: 0.00817100889980793 [35456/59904]\n",
      "loss: 0.10627475380897522 [41344/59904]\n",
      "loss: 0.019724028185009956 [47232/59904]\n",
      "loss: 0.020794326439499855 [53120/59904]\n",
      "loss: 0.0009050040971487761 [59008/59904]\n",
      "Avg error:  0.033956133\n",
      "Train Precision:  0.9914529914529915 \n",
      "\n",
      "Test Accuracy: 98.96334134615384 %\n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.021486422047019005 [128/59904]\n",
      "loss: 0.05627146363258362 [6016/59904]\n",
      "loss: 0.10722750425338745 [11904/59904]\n",
      "loss: 0.033721793442964554 [17792/59904]\n",
      "loss: 0.022139884531497955 [23680/59904]\n",
      "loss: 0.031204313039779663 [29568/59904]\n",
      "loss: 0.007529233582317829 [35456/59904]\n",
      "loss: 0.10077551752328873 [41344/59904]\n",
      "loss: 0.01912282593548298 [47232/59904]\n",
      "loss: 0.018833093345165253 [53120/59904]\n",
      "loss: 0.0008658746955916286 [59008/59904]\n",
      "Avg error:  0.032502927\n",
      "Train Precision:  0.9921541132478633 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.021050306037068367 [128/59904]\n",
      "loss: 0.05492490902543068 [6016/59904]\n",
      "loss: 0.1027776449918747 [11904/59904]\n",
      "loss: 0.031303953379392624 [17792/59904]\n",
      "loss: 0.02011682279407978 [23680/59904]\n",
      "loss: 0.02942192740738392 [29568/59904]\n",
      "loss: 0.00717588234692812 [35456/59904]\n",
      "loss: 0.09763319790363312 [41344/59904]\n",
      "loss: 0.018617207184433937 [47232/59904]\n",
      "loss: 0.01597627066075802 [53120/59904]\n",
      "loss: 0.0008537144749425352 [59008/59904]\n",
      "Avg error:  0.031199504\n",
      "Train Precision:  0.9925213675213675 \n",
      "\n",
      "Test Accuracy: 99.0234375 %\n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.020727254450321198 [128/59904]\n",
      "loss: 0.05085429549217224 [6016/59904]\n",
      "loss: 0.09861776977777481 [11904/59904]\n",
      "loss: 0.029712963849306107 [17792/59904]\n",
      "loss: 0.01812114007771015 [23680/59904]\n",
      "loss: 0.027700964361429214 [29568/59904]\n",
      "loss: 0.006829887628555298 [35456/59904]\n",
      "loss: 0.09391807019710541 [41344/59904]\n",
      "loss: 0.01817617006599903 [47232/59904]\n",
      "loss: 0.014396585524082184 [53120/59904]\n",
      "loss: 0.0008036891231313348 [59008/59904]\n",
      "Avg error:  0.029890815\n",
      "Train Precision:  0.9931056356837606 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.018950361758470535 [128/59904]\n",
      "loss: 0.04637325182557106 [6016/59904]\n",
      "loss: 0.09546386450529099 [11904/59904]\n",
      "loss: 0.02787681296467781 [17792/59904]\n",
      "loss: 0.01551341824233532 [23680/59904]\n",
      "loss: 0.026081761345267296 [29568/59904]\n",
      "loss: 0.006477159447968006 [35456/59904]\n",
      "loss: 0.0891030952334404 [41344/59904]\n",
      "loss: 0.016905315220355988 [47232/59904]\n",
      "loss: 0.013339041732251644 [53120/59904]\n",
      "loss: 0.0007658167742192745 [59008/59904]\n",
      "Avg error:  0.028666152\n",
      "Train Precision:  0.9935730502136753 \n",
      "\n",
      "Test Accuracy: 99.09021100427351 %\n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.017496442422270775 [128/59904]\n",
      "loss: 0.043441370129585266 [6016/59904]\n",
      "loss: 0.09031405299901962 [11904/59904]\n",
      "loss: 0.026567015796899796 [17792/59904]\n",
      "loss: 0.013167040422558784 [23680/59904]\n",
      "loss: 0.024530623108148575 [29568/59904]\n",
      "loss: 0.0062162685208022594 [35456/59904]\n",
      "loss: 0.08623363822698593 [41344/59904]\n",
      "loss: 0.016749991104006767 [47232/59904]\n",
      "loss: 0.01217973604798317 [53120/59904]\n",
      "loss: 0.0007444805232807994 [59008/59904]\n",
      "Avg error:  0.027521484\n",
      "Train Precision:  0.9939903846153846 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.016046369448304176 [128/59904]\n",
      "loss: 0.041673123836517334 [6016/59904]\n",
      "loss: 0.08613598346710205 [11904/59904]\n",
      "loss: 0.02567160315811634 [17792/59904]\n",
      "loss: 0.011535009369254112 [23680/59904]\n",
      "loss: 0.021442558616399765 [29568/59904]\n",
      "loss: 0.0058309826999902725 [35456/59904]\n",
      "loss: 0.0830671638250351 [41344/59904]\n",
      "loss: 0.01596057415008545 [47232/59904]\n",
      "loss: 0.011179441586136818 [53120/59904]\n",
      "loss: 0.0007533180760219693 [59008/59904]\n",
      "Avg error:  0.026419502\n",
      "Train Precision:  0.9944411057692307 \n",
      "\n",
      "Test Accuracy: 99.12192841880342 %\n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.01584630273282528 [128/59904]\n",
      "loss: 0.03849686682224274 [6016/59904]\n",
      "loss: 0.0842641070485115 [11904/59904]\n",
      "loss: 0.025018107146024704 [17792/59904]\n",
      "loss: 0.009498722851276398 [23680/59904]\n",
      "loss: 0.0194482933729887 [29568/59904]\n",
      "loss: 0.005594565067440271 [35456/59904]\n",
      "loss: 0.08068928122520447 [41344/59904]\n",
      "loss: 0.015001312829554081 [47232/59904]\n",
      "loss: 0.01054106093943119 [53120/59904]\n",
      "loss: 0.0007811427349224687 [59008/59904]\n",
      "Avg error:  0.025350103\n",
      "Train Precision:  0.9949586004273504 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.016205033287405968 [128/59904]\n",
      "loss: 0.0348387248814106 [6016/59904]\n",
      "loss: 0.08154422044754028 [11904/59904]\n",
      "loss: 0.023956628516316414 [17792/59904]\n",
      "loss: 0.00841091014444828 [23680/59904]\n",
      "loss: 0.018091857433319092 [29568/59904]\n",
      "loss: 0.005433139391243458 [35456/59904]\n",
      "loss: 0.07932615280151367 [41344/59904]\n",
      "loss: 0.014247632585465908 [47232/59904]\n",
      "loss: 0.009764541871845722 [53120/59904]\n",
      "loss: 0.0007464865921065211 [59008/59904]\n",
      "Avg error:  0.024337232\n",
      "Train Precision:  0.9953926282051282 \n",
      "\n",
      "Test Accuracy: 99.11858974358975 %\n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.01619919016957283 [128/59904]\n",
      "loss: 0.030693940818309784 [6016/59904]\n",
      "loss: 0.07757635414600372 [11904/59904]\n",
      "loss: 0.023469850420951843 [17792/59904]\n",
      "loss: 0.0076112402603030205 [23680/59904]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m-------------------------------\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m model.train()\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m loss, precision = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m losses.append(loss)\n\u001b[32m     17\u001b[39m train_precision.append(precision)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, x, y, batch_size, loss_fn, optim)\u001b[39m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m batch % \u001b[38;5;28mint\u001b[39m(num_batches/\u001b[32m10\u001b[39m) == \u001b[32m0\u001b[39m:\n\u001b[32m     27\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mloss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(batch+\u001b[32m1\u001b[39m)*batch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size*num_batches\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)   \n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     \u001b[43mloss_fn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m     optim.step()\n\u001b[32m     32\u001b[39m total_loss /= num_batches\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI_FRAMEWORK/NN/PY/framework.py:369\u001b[39m, in \u001b[36mCrossEntropy.backward\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI_FRAMEWORK/NN/PY/framework.py:47\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient)\u001b[39m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28mself\u001b[39m.creators[\u001b[32m0\u001b[39m].backward(\u001b[38;5;28mself\u001b[39m.gradient.transpose())\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.creation_op == \u001b[33m\"\u001b[39m\u001b[33mdot\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     46\u001b[39m     \u001b[38;5;66;03m# Gradient of weights\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreators\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreators\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# Gradient of input\u001b[39;00m\n\u001b[32m     49\u001b[39m     \u001b[38;5;28mself\u001b[39m.creators[\u001b[32m1\u001b[39m].backward(\u001b[38;5;28mself\u001b[39m.gradient.transpose().dot(\u001b[38;5;28mself\u001b[39m.creators[\u001b[32m0\u001b[39m]).transpose())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI_FRAMEWORK/NN/PY/framework.py:56\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient)\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28mself\u001b[39m.creators[\u001b[32m1\u001b[39m].backward(\u001b[38;5;28mself\u001b[39m.gradient.reshape((-\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.gradient.shape[-\u001b[32m1\u001b[39m])).dot(\u001b[38;5;28mself\u001b[39m.creators[\u001b[32m0\u001b[39m].reshape((\u001b[38;5;28mself\u001b[39m.creators[\u001b[32m0\u001b[39m].shape[\u001b[32m0\u001b[39m], -\u001b[32m1\u001b[39m))).transpose())\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.creation_op == \u001b[33m\"\u001b[39m\u001b[33mmul\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreators\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreators\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mself\u001b[39m.creators[\u001b[32m1\u001b[39m].backward(\u001b[38;5;28mself\u001b[39m.gradient * \u001b[38;5;28mself\u001b[39m.creators[\u001b[32m0\u001b[39m])\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.creation_op == \u001b[33m\"\u001b[39m\u001b[33mdiv\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI_FRAMEWORK/NN/PY/framework.py:66\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient)\u001b[39m\n\u001b[32m     64\u001b[39m creator = \u001b[38;5;28mself\u001b[39m.creators[\u001b[32m0\u001b[39m]\n\u001b[32m     65\u001b[39m sqr = np.sqrt(creator.var + creator.epsilon)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreators\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43msqr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m creator.gamma.backward(Tensor(\u001b[38;5;28mself\u001b[39m.gradient.data * (\u001b[38;5;28mself\u001b[39m.creators[\u001b[32m1\u001b[39m].data-creator.mean)/sqr))\n\u001b[32m     68\u001b[39m creator.beta.backward(\u001b[38;5;28mself\u001b[39m.gradient)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI_FRAMEWORK/NN/PY/framework.py:47\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient)\u001b[39m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28mself\u001b[39m.creators[\u001b[32m0\u001b[39m].backward(\u001b[38;5;28mself\u001b[39m.gradient.transpose())\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.creation_op == \u001b[33m\"\u001b[39m\u001b[33mdot\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     46\u001b[39m     \u001b[38;5;66;03m# Gradient of weights\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreators\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreators\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# Gradient of input\u001b[39;00m\n\u001b[32m     49\u001b[39m     \u001b[38;5;28mself\u001b[39m.creators[\u001b[32m1\u001b[39m].backward(\u001b[38;5;28mself\u001b[39m.gradient.transpose().dot(\u001b[38;5;28mself\u001b[39m.creators[\u001b[32m0\u001b[39m]).transpose())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI_FRAMEWORK/NN/PY/framework.py:66\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient)\u001b[39m\n\u001b[32m     64\u001b[39m creator = \u001b[38;5;28mself\u001b[39m.creators[\u001b[32m0\u001b[39m]\n\u001b[32m     65\u001b[39m sqr = np.sqrt(creator.var + creator.epsilon)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreators\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43msqr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m creator.gamma.backward(Tensor(\u001b[38;5;28mself\u001b[39m.gradient.data * (\u001b[38;5;28mself\u001b[39m.creators[\u001b[32m1\u001b[39m].data-creator.mean)/sqr))\n\u001b[32m     68\u001b[39m creator.beta.backward(\u001b[38;5;28mself\u001b[39m.gradient)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI_FRAMEWORK/NN/PY/framework.py:111\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient)\u001b[39m\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# sect = self.creators[0]\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# x = self.creators[1]\u001b[39;00m\n\u001b[32m     90\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    104\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    105\u001b[39m     \u001b[38;5;66;03m# x.backward(tns_ng)\u001b[39;00m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.creation_op == \u001b[33m\"\u001b[39m\u001b[33mreshape\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreators\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreators\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.creation_op == \u001b[33m\"\u001b[39m\u001b[33mget_max2d\u001b[39m\u001b[33m\"\u001b[39m: \n\u001b[32m    113\u001b[39m     init = time.time()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI_FRAMEWORK/NN/PY/framework.py:123\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\" print(\"Maxpool grad time:\", time.time() - init) \"\"\"\u001b[39;00m\n\u001b[32m    121\u001b[39m new_gradient[idxs] += \u001b[38;5;28mself\u001b[39m.gradient.data.flatten()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m x.backward(\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_gradient\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI_FRAMEWORK/NN/PY/framework.py:20\u001b[39m, in \u001b[36mTensor.__init__\u001b[39m\u001b[34m(self, data, creators, creation_op, autograd, is_parameter)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTensor\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, creators=\u001b[38;5;28;01mNone\u001b[39;00m, creation_op=\u001b[38;5;28;01mNone\u001b[39;00m, autograd=\u001b[38;5;28;01mTrue\u001b[39;00m, is_parameter=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m     21\u001b[39m         \u001b[38;5;28mself\u001b[39m.data = np.array(data, dtype=np.float32)\n\u001b[32m     22\u001b[39m         \u001b[38;5;28mself\u001b[39m.shape = \u001b[38;5;28mself\u001b[39m.data.shape\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "losses = []\n",
    "train_precision = []\n",
    "\n",
    "test_precision = []\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "    model.train()\n",
    "\n",
    "    loss, precision = train(model, train_image, train_label, 128, loss_fn, optim)\n",
    "    \n",
    "    losses.append(loss)\n",
    "    train_precision.append(precision)\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        model.test()\n",
    "        precision = test(model, test_image, test_label, 128)\n",
    "\n",
    "        test_precision.append(precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(0, len(test_precision)), test_precision, \"g*--\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object saved successfully.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"99_12precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import framework as fm \n",
    "import numpy as np \n",
    "import pandas as np\n",
    "\n",
    "with open('97precision.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "print(\"Object loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.24712873931624 %\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "model.test()\n",
    "correct = 0\n",
    "batch_size = 128\n",
    "num_batches = int(len(train_label)/batch_size)\n",
    "for batch in range(num_batches):\n",
    "        batch_start, batch_end = (batch * batch_size, (batch + 1) * batch_size)\n",
    "\n",
    "        inpt = fm.Tensor(test_image[batch_start:batch_end])\n",
    "        label = fm.Tensor(test_label[batch_start:batch_end])\n",
    "        \n",
    "        pred = model.forward(inpt)\n",
    "\n",
    "        pred_nums = np.argmax(pred.data, axis=1)\n",
    "        label_nums = np.argmax(label.data, axis=1)\n",
    "\n",
    "        correct += (pred_nums == label_nums).sum()\n",
    "\n",
    "print(\"Accuracy:\", correct / (batch_size * num_batches) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [2663]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:3838 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:48198 - \"POST /predict HTTP/1.1\" 500 Internal Server Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eric/miniforge3/lib/python3.12/site-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/eric/miniforge3/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/eric/miniforge3/lib/python3.12/site-packages/fastapi/applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"/home/eric/miniforge3/lib/python3.12/site-packages/starlette/applications.py\", line 112, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"/home/eric/miniforge3/lib/python3.12/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n",
      "    raise exc\n",
      "  File \"/home/eric/miniforge3/lib/python3.12/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"/home/eric/miniforge3/lib/python3.12/site-packages/starlette/middleware/cors.py\", line 93, in __call__\n",
      "    await self.simple_response(scope, receive, send, request_headers=headers)\n",
      "  File \"/home/eric/miniforge3/lib/python3.12/site-packages/starlette/middleware/cors.py\", line 144, in simple_response\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"/home/eric/miniforge3/lib/python3.12/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"/home/eric/miniforge3/lib/python3.12/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"/home/eric/miniforge3/lib/python3.12/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"/home/eric/miniforge3/lib/python3.12/site-packages/starlette/routing.py\", line 714, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"/home/eric/miniforge3/lib/python3.12/site-packages/starlette/routing.py\", line 734, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"/home/eric/miniforge3/lib/python3.12/site-packages/starlette/routing.py\", line 288, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"/home/eric/miniforge3/lib/python3.12/site-packages/starlette/routing.py\", line 76, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"/home/eric/miniforge3/lib/python3.12/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"/home/eric/miniforge3/lib/python3.12/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"/home/eric/miniforge3/lib/python3.12/site-packages/starlette/routing.py\", line 73, in app\n",
      "    response = await f(request)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/eric/miniforge3/lib/python3.12/site-packages/fastapi/routing.py\", line 301, in app\n",
      "    raw_response = await run_endpoint_function(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/eric/miniforge3/lib/python3.12/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n",
      "    return await dependant.call(**values)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_2663/1124103067.py\", line 21, in predict\n",
      "    num = int(np.argmax(pred.data, axis=1))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: only length-1 arrays can be converted to Python scalars\n"
     ]
    }
   ],
   "source": [
    "import uvicorn\n",
    "from fastapi import Request, FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import nest_asyncio\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "async def predict(request: Request):\n",
    "    res = await request.json()\n",
    "    picture = fm.Tensor(np.array(res).reshape((1, 1, 28, 28)))\n",
    "    pred = model.forward(picture)\n",
    "    num = int(np.argmax(pred.data, axis=1))\n",
    "\n",
    "    return num\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    nest_asyncio.apply()  # Allow asyncio.run to work in a running loop\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=3838)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:  [[0.5488135  0.71518934 0.60276335 0.5448832  0.4236548  0.6458941\n",
      "  0.4375872  0.891773   0.96366274 0.3834415 ]]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 1. 0. 1.]]\n",
      "Res:  [[0.        0.        0.        0.5448832 0.        0.        0.\n",
      "  0.891773  0.        0.3834415]]\n",
      "Data Loss:  [[0. 0. 0. 1. 0. 0. 0. 1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import framework as fm\n",
    "\n",
    "np.random.seed(0)\n",
    "data = fm.Tensor(np.random.random((1, 10)))\n",
    "drop = fm.Dropout(0.2)\n",
    "drop.training = True\n",
    "\n",
    "res = drop.forward(data)\n",
    "\n",
    "loss = fm.Tensor(np.ones((data.data.shape)))\n",
    "\n",
    "print(\"Data: \", data)\n",
    "\n",
    "print(drop.mask)\n",
    "\n",
    "print(\"Res: \", res)\n",
    "\n",
    "res.backward(loss)\n",
    "\n",
    "print(\"Data Loss: \", data.gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 272 ms, sys: 32.4 ms, total: 304 ms\n",
      "Wall time: 105 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], shape=(100, 26, 26))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "import framework as fm\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "conv = fm.Conv2dC(1, 100, 3, 1, bias = False)\n",
    "x = np.random.random((100, 1, 28, 28))\n",
    "res = conv.forward(fm.Tensor(x))\n",
    "\n",
    "count = sum(res.data == 0)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
